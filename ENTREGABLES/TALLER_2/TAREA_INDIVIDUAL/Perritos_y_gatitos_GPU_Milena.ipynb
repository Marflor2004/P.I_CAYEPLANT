{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Instalación del paquete `kaggle`\n",
        "\n",
        "El siguiente comando instala la biblioteca `kaggle` en el entorno de Google Colab:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qysebIP01GGN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m2TwL79z60c",
        "outputId": "1081671c-1be9-427a-efdd-25255ffae633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Subida de Archivos a Google Colab\n",
        "\n",
        "El siguiente código se utiliza para subir archivos desde tu computadora local al entorno de Google Colab.\n",
        "\n",
        "### 1. Importación del Módulo `files` desde `google.colab`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nKN-LcRV1WhF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "MV6hxNit0ZBA",
        "outputId": "5b1c06d8-6f5e-4214-8189-2f47df906026"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a35d9dbe-be70-4a43-ac27-ef9530d1348b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a35d9dbe-be70-4a43-ac27-ef9530d1348b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    165\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rG0iNZlX-Gvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### Configuración de las Credenciales de Kaggle\n",
        "\n",
        "El siguiente conjunto de comandos se utiliza para configurar las credenciales de Kaggle en un entorno de Google Colab. Esto es necesario para poder descargar datasets y participar en competiciones directamente desde Kaggle usando scripts de Python.\n",
        "\n",
        "### 1. Crear un Directorio `.kaggle`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_DX0LBk81YTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L4iZGMws0dX5"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Descarga y Descompresión de un Dataset desde Kaggle\n",
        "\n",
        "Este conjunto de comandos se utiliza para descargar un dataset de Kaggle y descomprimirlo en el entorno de Google Colab.\n",
        "\n",
        "### 1. Descargar un Dataset desde Kaggle\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zGgXrOyS1aVO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RDOW3jP00ghh"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d hongweicao/catanddogsmall\n",
        "!unzip catanddogsmall.zip -d cats_and_dogs_small"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### Actualización de TensorFlow\n",
        "\n",
        "El siguiente comando se utiliza para actualizar la biblioteca `TensorFlow` a su última versión en el entorno de Google Colab.\n",
        "\n",
        "### 1. Actualización de TensorFlow\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sIZsmciR1azv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qHmvCpUoAeRk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1dGvp_wC0ocY"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### Verificación de GPUs Disponibles\n",
        "\n",
        "El siguiente código se utiliza para verificar cuántas GPUs están disponibles en el entorno de Google Colab.\n",
        "\n",
        "### 1. Importación del Módulo `tensorflow`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "awMp50Ee1bG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "glq-Z9Nq2dhg"
      },
      "outputs": [],
      "source": [
        "# Verificar entorno de ejecución\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Configuración de Matplotlib para la Visualización de Gráficos\n",
        "\n",
        "El siguiente código se utiliza para configurar cómo se muestran los gráficos generados con Matplotlib en un entorno de notebook, como Google Colab.\n",
        "\n",
        "### 1. Mostrar Gráficos Inline\n",
        "\n"
      ],
      "metadata": {
        "id": "EEu1rW5R1b6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KBwG2QA63HNJ"
      },
      "outputs": [],
      "source": [
        "#Configurar el entorno de ejecución\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Importación de Bibliotecas para Análisis y Visualización de Datos\n",
        "\n",
        "El siguiente código importa varias bibliotecas esenciales para análisis y visualización de datos, y establece un estilo gráfico para Matplotlib.\n",
        "\n",
        "### 1. Importar `matplotlib.pyplot`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hv7_MPqp1dL1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ulf2guZq3KNi"
      },
      "outputs": [],
      "source": [
        "#Importación de librerias\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Configuración de la Gestión de Advertencias\n",
        "\n",
        "El siguiente código se utiliza para configurar el manejo de advertencias en un entorno de Python.\n",
        "\n",
        "### 1. Importar el Módulo `warnings`\n",
        "\n"
      ],
      "metadata": {
        "id": "hhD23RAn1dzG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2HH5Mawh_dN8"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Configuración de Opciones de Visualización de Pandas\n",
        "\n",
        "El siguiente código configura cómo se muestran los datos en los DataFrames de `pandas`, ajustando el formato de los números y el número máximo de filas y columnas que se pueden visualizar.\n",
        "\n",
        "### 1. Configurar el Formato de los Números Flotantes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fOM7Vr5g1ecH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2frZSXvgAGdj"
      },
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Importación de Componentes de Keras para Modelado y Preprocesamiento\n",
        "\n",
        "El siguiente código importa diversas clases y funciones de la biblioteca `tensorflow.keras`, que se utiliza para construir, entrenar y evaluar modelos de deep learning, así como para preprocesar datos de imágenes.\n",
        "\n",
        "### 1. Importar Modelos y Funciones de Keras\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fiVsis8F1fK4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JrTJL2RsAOXT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Funciones para Procesamiento y Visualización en Modelos de Deep Learning\n",
        "\n",
        "A continuación se describen varias funciones útiles para el análisis y procesamiento de datos de entrenamiento en modelos de deep learning.\n"
      ],
      "metadata": {
        "id": "_XTFqBp11fle"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P1R-wLycMCZT"
      },
      "outputs": [],
      "source": [
        "def smooth_curve(points, factor=0.8):\n",
        "    smoothed = []\n",
        "    for point in points:\n",
        "        if smoothed:\n",
        "            previous = smoothed[-1]\n",
        "            smoothed.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed.append(point)\n",
        "    return smoothed\n",
        "\n",
        "def plot_compare(history, steps=-1):\n",
        "    if steps < 0:\n",
        "        steps = len(history.history.get('accuracy', []))\n",
        "    acc = smooth_curve(history.history.get('accuracy', [])[:steps])\n",
        "    val_acc = smooth_curve(history.history.get('val_accuracy', [])[:steps])\n",
        "    loss = smooth_curve(history.history.get('loss', [])[:steps])\n",
        "    val_loss = smooth_curve(history.history.get('val_loss', [])[:steps])\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(loss, c='#0c7cba', label='Train Loss')\n",
        "    plt.plot(val_loss, c='#0f9d58', label='Val Loss')\n",
        "    plt.xticks(range(0, len(loss), max(1, len(loss)//10)))\n",
        "    plt.xlim(0, len(loss))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Train Loss: {loss[-1]:.3f}, Val Loss: {val_loss[-1]:.3f}', fontsize=12)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(acc, c='#0c7cba', label='Train Acc')\n",
        "    plt.plot(val_acc, c='#0f9d58', label='Val Acc')\n",
        "    plt.xticks(range(0, len(acc), max(1, len(acc)//10)))\n",
        "    plt.xlim(0, len(acc))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'Train Accuracy: {acc[-1]:.3f}, Val Accuracy: {val_acc[-1]:.3f}', fontsize=12)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def deprocess_image(x):\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "    x *= 255\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def save_history(history, fn):\n",
        "    try:\n",
        "        with open(fn, 'wb') as fw:\n",
        "            pickle.dump(history.history, fw, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving history: {e}\")\n",
        "\n",
        "def load_history(fn):\n",
        "    class Temp:\n",
        "        pass\n",
        "    history = Temp()\n",
        "    try:\n",
        "        with open(fn, 'rb') as fr:\n",
        "            history.history = pickle.load(fr)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading history: {e}\")\n",
        "    return history\n",
        "\n",
        "def jitter(img, amount=32):\n",
        "    ox, oy = np.random.randint(-amount, amount + 1, 2)\n",
        "    return np.roll(np.roll(img, ox, axis=1), oy, axis=0), ox, oy\n",
        "\n",
        "def reverse_jitter(img, ox, oy):\n",
        "    return np.roll(np.roll(img, -ox, axis=1), -oy, axis=0)\n",
        "\n",
        "def plot_image(img, title=''):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición y Compilación del Modelo en Keras\n",
        "\n",
        "### 1. Importar Librerías Necesarias\n",
        "\n",
        "Este código utiliza `Sequential`, `Conv2D`, `MaxPooling2D`, `Flatten`, `Dropout`, y `Dense` de `tensorflow.keras`, que son componentes esenciales para construir y entrenar redes neuronales convolucionales.\n",
        "\n",
        "### 2. Definir el Modelo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zHn0Cavc1gVU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Un8kcGL1NYSv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Definir el modelo\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1',\n",
        "                 input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D((2, 2), name='maxpool_1'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='conv_2'))\n",
        "model.add(MaxPooling2D((2, 2), name='maxpool_2'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_3'))\n",
        "model.add(MaxPooling2D((2, 2), name='maxpool_3'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_4'))\n",
        "model.add(MaxPooling2D((2, 2), name='maxpool_4'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu', name='dense_1'))\n",
        "model.add(Dense(256, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de Directorios de Datos\n",
        "\n",
        "El siguiente código establece las rutas a los directorios que contienen los datos de entrenamiento, validación y prueba para el modelo. Estos directorios son cruciales para cargar y organizar los datos de manera adecuada durante el entrenamiento y la evaluación del modelo.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g51KJI4k1gto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G2hDPXb4Noh8"
      },
      "outputs": [],
      "source": [
        "# Directorios de datos\n",
        "base_dir = '/content/cats_and_dogs_small/dogvscat_small'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FdQxxLXQ1hfx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pDvaA42fkQKM"
      },
      "outputs": [],
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1WM5Nzo71ik6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Sg1MHoxWinEy"
      },
      "outputs": [],
      "source": [
        "#Contar imágenes de entrenamiento y validación\n",
        "def count_images(directory):\n",
        "    count = 0\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "train_image_count = count_images(train_dir)\n",
        "validation_image_count = count_images(validation_dir)\n",
        "print(f\"Number of training images: {train_image_count}\")\n",
        "print(f\"Number of validation images: {validation_image_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wCldN5wg1jCc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uFRgNuM6iu-3"
      },
      "outputs": [],
      "source": [
        "#Calcular los lotes por épocas\n",
        "batch_size = 20\n",
        "train_batches_per_epoch = train_image_count // batch_size\n",
        "validation_batches_per_epoch = validation_image_count // batch_size\n",
        "print(f\"Number of batches per epoch for training: {train_batches_per_epoch}\")\n",
        "print(f\"Number of batches per epoch for validation: {validation_batches_per_epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eUlVVBJ71jkM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R-brV073ee4t"
      },
      "outputs": [],
      "source": [
        "# Verificar que los directorios existan\n",
        "for directory in [train_dir, validation_dir, test_dir]:\n",
        "    if not os.path.exists(directory):\n",
        "        raise FileNotFoundError(f\"Directorio no encontrado: {directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iitMKQvq1kGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JqdB18DDfwnm"
      },
      "outputs": [],
      "source": [
        "!ls /content/cats_and_dogs_small/dogvscat_small"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JW-SXQB41ktN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yBZ9r5sQefIG"
      },
      "outputs": [],
      "source": [
        "# Preparación de los generadores de datos\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vbthY5V-1loU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UEODetq7mI0Z"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=10,  # Número de lotes por época\n",
        "    epochs=10,  # Número total de épocas\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=5,  # Número de lotes de validación por época\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V42KeZNi1l-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8OYTfob9mI3c"
      },
      "outputs": [],
      "source": [
        "model.save('model.keras')\n",
        "save_history(history, 'history.bin')\n",
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zAoyJAA11mn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KrnjsuTc5yi1"
      },
      "outputs": [],
      "source": [
        "history = load_history('history.bin')\n",
        "plot_compare(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fb1H7RKM1nKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nw3R4JmA5ymW"
      },
      "outputs": [],
      "source": [
        "model_aug = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2), name='maxpool_1'),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same', name='conv_2'),\n",
        "    MaxPooling2D((2, 2), name='maxpool_2'),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_3'),\n",
        "    MaxPooling2D((2, 2), name='maxpool_3'),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_4'),\n",
        "    MaxPooling2D((2, 2), name='maxpool_4'),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu', name='dense_1'),\n",
        "    Dense(256, activation='relu', name='dense_2'),\n",
        "    Dense(1, activation='sigmoid', name='output')\n",
        "])\n",
        "\n",
        "model_aug.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KD5SKPAg1nn_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WJbY3TAc5ypw"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IrVBPeJs1n9g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W77AvWTH5ys-"
      },
      "outputs": [],
      "source": [
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rpm0Lg021oS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MaMPjnIf5ywQ"
      },
      "outputs": [],
      "source": [
        "# early_stop = EarlyStopping(monitor='val_loss', patience=6, verbose=1)\n",
        "######################################### change the values 100, 60 and 50\n",
        "history_aug = model_aug.fit(train_generator, steps_per_epoch=100, epochs=60,\n",
        "                                      validation_data=validation_generator, validation_steps=50, verbose=1)\n",
        "#history_aug = model_aug.fit(train_generator, steps_per_epoch=100, epochs=60,\n",
        "#                                      validation_data=validation_generator, validation_steps=50, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nTe3Vu3Y1os3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca6Aw0__5yzF"
      },
      "outputs": [],
      "source": [
        "model_aug.save('model_aug.keras')\n",
        "save_history(history_aug, 'history_aug.bin')\n",
        "print(history_aug.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4XplhNJA1pFM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHfODJDQmI9e"
      },
      "outputs": [],
      "source": [
        "history_aug = load_history('history_aug.bin')\n",
        "plot_compare(history_aug, steps=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xiL1fNGi1pXA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS7otsOCMyC6"
      },
      "outputs": [],
      "source": [
        "# Evaluar el modelo en el conjunto de validación\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ARnppPxT1p92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtQTHwqOMyGA"
      },
      "outputs": [],
      "source": [
        "# Realizar predicciones con el modelo\n",
        "sample_image_path = '/content/cats_and_dogs_small/dogvscat_small/train/cats/53.jpg'\n",
        "img = image.load_img(sample_image_path, target_size=(150, 150))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Rescale"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KQO8hlCV1qXF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh9Wvd39MyIi"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(img_array)\n",
        "print(f'Predicción: {\"Perro\" if prediction[0] > 0.5 else \"Gato\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QiFZ2ehn1qxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU_SuiZrMyOC"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img_array[0])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZFXNNgdU1rIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd6heiNRMyQU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Load the VGG16 model with ImageNet weights, without the top classification layer\n",
        "vgg = VGG16(weights='imagenet', include_top=False)\n",
        "vgg.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y0O4-lWz1r4g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkKYCjiZSD_r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KKbSJ9qD1sIi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFKod86gRkIX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the VGG16 model with ImageNet weights, without the top classification layer\n",
        "vgg = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Extract the outputs of the convolutional layers\n",
        "layer_outputs = [layer.output for layer in vgg.layers if 'conv1' in layer.name]\n",
        "\n",
        "# Create a new model that outputs the features from the specified layers\n",
        "activation_model = Model(inputs=vgg.input, outputs=layer_outputs)\n",
        "\n",
        "# Assuming img_tensor is the preprocessed image tensor\n",
        "intermediate_activations = activation_model.predict(img_array)\n",
        "\n",
        "first_layer_activation = intermediate_activations[0]\n",
        "\n",
        "plt.imshow(first_layer_activation[0, :, :, 19], cmap='viridis')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AtDKXjlk2c1v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFx6NMvWRkLb"
      },
      "outputs": [],
      "source": [
        "layer_names = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "\n",
        "layer_outputs = [layer.output for layer in vgg.layers if layer.name in layer_names]\n",
        "activation_model = Model(inputs=vgg.input, outputs=layer_outputs)\n",
        "intermediate_activations = activation_model.predict(img_array)\n",
        "\n",
        "images_per_row = 8\n",
        "max_images = 8\n",
        "# Now let's display our feature maps\n",
        "for layer_name, layer_activation in zip(layer_names, intermediate_activations):\n",
        "    # This is the number of features in the feature map\n",
        "    n_features = layer_activation.shape[-1]\n",
        "    n_features = min(n_features, max_images)\n",
        "\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # We will tile the activation channels in this matrix\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    # We'll tile each filter into this big horizontal grid\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # Post-process the feature to make it visually palatable\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    # Display the grid\n",
        "    scale = 2. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                        scale * display_grid.shape[0]))\n",
        "    plt.axis('off')\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZDRdVsFB2eRG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiXZnlwWRkOG"
      },
      "outputs": [],
      "source": [
        "# Cargar el modelo VGG16 con pesos preentrenados de ImageNet\n",
        "model = VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "# Buscar el índice de la capa 'predictions' por nombre\n",
        "layer_idx = None\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if layer.name == 'predictions':\n",
        "        layer_idx = i\n",
        "        break\n",
        "\n",
        "if layer_idx is None:\n",
        "    raise ValueError(\"Layer 'predictions' not found in the model.\")\n",
        "\n",
        "# Cambiar la activación softmax a lineal\n",
        "model.layers[layer_idx].activation = activations.linear"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pXsvQPBa2e8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zuw9mF7RkTw"
      },
      "outputs": [],
      "source": [
        "from tf_keras_vis.activation_maximization import ActivationMaximization\n",
        "from tf_keras_vis.utils.callbacks import Print\n",
        "\n",
        "# Definir la función de pérdida para maximizar la activación del filtro 20\n",
        "def loss(output):\n",
        "    return output[:, 20]\n",
        "\n",
        "# Configurar la visualización de activaciones\n",
        "activation_maximization = ActivationMaximization(model, model_modifier=None, clone=False)\n",
        "\n",
        "# Visualizar la activación del filtro (por ejemplo, el filtro 20)\n",
        "img = activation_maximization(loss, callbacks=[Print(interval=50)])\n",
        "\n",
        "# Mostrar la imagen generada\n",
        "plot_image(img[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4LaETD7G2fUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvEZKbJ2RkWi"
      },
      "outputs": [],
      "source": [
        "from tf_keras_vis.utils.modifiers import Jitter\n",
        "\n",
        "# Definir la función de pérdida para maximizar la activación del filtro 20 (ouzel)\n",
        "def loss(output):\n",
        "    return output[:, 20]  # 20 es la categoría de ImageNet para 'ouzel'\n",
        "\n",
        "# Configurar la visualización de activaciones con jitter\n",
        "activation_maximization = ActivationMaximization(model, model_modifier=None, clone=False)\n",
        "\n",
        "# Aplicar jitter de 16 píxeles durante el proceso de optimización\n",
        "img = activation_maximization(\n",
        "    loss,\n",
        "    callbacks=[Print(interval=50)],\n",
        "    input_modifiers=[Jitter(16)],  # Jitter de 16 píxeles\n",
        "    steps=400  # Número de iteraciones para optimizar\n",
        ")\n",
        "\n",
        "# Mostrar la imagen generada\n",
        "plot_image(img[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKdoRa-eRkZp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUwZoXHORkeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTL_g7Ngkaxe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}